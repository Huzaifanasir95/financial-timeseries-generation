{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbc9c1c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Technical indicators library\n",
    "try:\n",
    "    import ta\n",
    "    print(\"‚úÖ 'ta' library available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Installing 'ta' library...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'ta'])\n",
    "    import ta\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÖ Feature Engineering Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4a006",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "PROCESSED_DATA_DIR = '../../data/processed'\n",
    "FEATURES_DATA_DIR = '../../data/features'\n",
    "FIGURES_DIR = '../../outputs/figures'\n",
    "os.makedirs(FEATURES_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Ticker lists (25 assets)\n",
    "TICKERS = {\n",
    "    'indices': ['GSPC', 'IXIC', 'DJI', 'FTSE', 'N225', 'HSI', 'GDAXI'],\n",
    "    'stocks': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'JPM', 'XOM', 'JNJ', 'V', 'WMT', 'PG'],\n",
    "    'crypto': ['BTC_USD', 'ETH_USD', 'BNB_USD', 'SOL_USD', 'ADA_USD'],\n",
    "    'commodities': ['GC=F', 'CL=F']\n",
    "}\n",
    "\n",
    "ALL_TICKERS = [ticker for tickers in TICKERS.values() for ticker in tickers]\n",
    "\n",
    "# Feature engineering parameters\n",
    "WINDOWS = [5, 10, 20, 50]  # Window sizes for rolling features\n",
    "LAG_PERIODS = [1, 5, 10, 20]  # Lag periods for autoregressive features\n",
    "\n",
    "print(f\"üìÇ Processed data directory: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"üìÇ Features data directory: {FEATURES_DATA_DIR}\")\n",
    "print(f\"üìä Total assets: {len(ALL_TICKERS)}\")\n",
    "print(f\"üîß Window sizes: {WINDOWS}\")\n",
    "print(f\"üîß Lag periods: {LAG_PERIODS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f01f0",
   "metadata": {},
   "source": [
    "## 3. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93499d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all processed data\n",
    "print(\"üì• Loading processed data...\\n\")\n",
    "\n",
    "data = {}\n",
    "\n",
    "for ticker in ALL_TICKERS:\n",
    "    try:\n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, f\"{ticker}_processed.csv\")\n",
    "        df = pd.read_csv(filepath, index_col=0, parse_dates=True)\n",
    "        data[ticker] = df\n",
    "        print(f\"‚úÖ {ticker:10s} - {len(df):,} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {ticker:10s} - Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(data)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8ce20",
   "metadata": {},
   "source": [
    "## 4. Technical Indicators Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_momentum_indicators(df):\n",
    "    \"\"\"\n",
    "    Add momentum technical indicators.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with added momentum indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # RSI (Relative Strength Index) - 14 day\n",
    "    df['RSI_14'] = ta.momentum.RSIIndicator(close=df['Close'], window=14).rsi()\n",
    "    \n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    macd = ta.trend.MACD(close=df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_Signal'] = macd.macd_signal()\n",
    "    df['MACD_Diff'] = macd.macd_diff()\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    stoch = ta.momentum.StochasticOscillator(high=df['High'], low=df['Low'], close=df['Close'])\n",
    "    df['Stoch_K'] = stoch.stoch()\n",
    "    df['Stoch_D'] = stoch.stoch_signal()\n",
    "    \n",
    "    # Rate of Change (ROC)\n",
    "    df['ROC_10'] = ta.momentum.ROCIndicator(close=df['Close'], window=10).roc()\n",
    "    \n",
    "    # Williams %R\n",
    "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high=df['High'], low=df['Low'], \n",
    "                                                        close=df['Close'], lbp=14).williams_r()\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Momentum indicators function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trend_indicators(df):\n",
    "    \"\"\"\n",
    "    Add trend technical indicators.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Simple Moving Averages\n",
    "    df['SMA_5'] = ta.trend.SMAIndicator(close=df['Close'], window=5).sma_indicator()\n",
    "    df['SMA_10'] = ta.trend.SMAIndicator(close=df['Close'], window=10).sma_indicator()\n",
    "    df['SMA_20'] = ta.trend.SMAIndicator(close=df['Close'], window=20).sma_indicator()\n",
    "    df['SMA_50'] = ta.trend.SMAIndicator(close=df['Close'], window=50).sma_indicator()\n",
    "    \n",
    "    # Exponential Moving Averages\n",
    "    df['EMA_5'] = ta.trend.EMAIndicator(close=df['Close'], window=5).ema_indicator()\n",
    "    df['EMA_10'] = ta.trend.EMAIndicator(close=df['Close'], window=10).ema_indicator()\n",
    "    df['EMA_20'] = ta.trend.EMAIndicator(close=df['Close'], window=20).ema_indicator()\n",
    "    \n",
    "    # Average Directional Index (ADX)\n",
    "    adx = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'])\n",
    "    df['ADX'] = adx.adx()\n",
    "    df['ADX_Pos'] = adx.adx_pos()\n",
    "    df['ADX_Neg'] = adx.adx_neg()\n",
    "    \n",
    "    # Ichimoku Cloud\n",
    "    ichimoku = ta.trend.IchimokuIndicator(high=df['High'], low=df['Low'])\n",
    "    df['Ichimoku_A'] = ichimoku.ichimoku_a()\n",
    "    df['Ichimoku_B'] = ichimoku.ichimoku_b()\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Trend indicators function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff31cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_volatility_indicators(df):\n",
    "    \"\"\"\n",
    "    Add volatility technical indicators.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bollinger = ta.volatility.BollingerBands(close=df['Close'], window=20, window_dev=2)\n",
    "    df['BB_High'] = bollinger.bollinger_hband()\n",
    "    df['BB_Low'] = bollinger.bollinger_lband()\n",
    "    df['BB_Mid'] = bollinger.bollinger_mavg()\n",
    "    df['BB_Width'] = bollinger.bollinger_wband()\n",
    "    df['BB_Pct'] = bollinger.bollinger_pband()\n",
    "    \n",
    "    # Average True Range (ATR)\n",
    "    df['ATR_14'] = ta.volatility.AverageTrueRange(high=df['High'], low=df['Low'], \n",
    "                                                    close=df['Close'], window=14).average_true_range()\n",
    "    \n",
    "    # Keltner Channel\n",
    "    keltner = ta.volatility.KeltnerChannel(high=df['High'], low=df['Low'], close=df['Close'])\n",
    "    df['Keltner_High'] = keltner.keltner_channel_hband()\n",
    "    df['Keltner_Low'] = keltner.keltner_channel_lband()\n",
    "    df['Keltner_Mid'] = keltner.keltner_channel_mband()\n",
    "    \n",
    "    # Historical Volatility (rolling std of returns, annualized)\n",
    "    df['HV_20'] = df['Returns'].rolling(window=20).std() * np.sqrt(252)\n",
    "    df['HV_50'] = df['Returns'].rolling(window=50).std() * np.sqrt(252)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Volatility indicators function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_volume_indicators(df):\n",
    "    \"\"\"\n",
    "    Add volume technical indicators.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # On-Balance Volume (OBV)\n",
    "    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume']).on_balance_volume()\n",
    "    \n",
    "    # Volume Moving Averages\n",
    "    df['Volume_SMA_10'] = df['Volume'].rolling(window=10).mean()\n",
    "    df['Volume_SMA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # Volume Rate of Change\n",
    "    df['Volume_ROC'] = df['Volume'].pct_change(periods=10)\n",
    "    \n",
    "    # Money Flow Index (MFI)\n",
    "    df['MFI'] = ta.volume.MFIIndicator(high=df['High'], low=df['Low'], \n",
    "                                        close=df['Close'], volume=df['Volume']).money_flow_index()\n",
    "    \n",
    "    # Chaikin Money Flow\n",
    "    df['CMF'] = ta.volume.ChaikinMoneyFlowIndicator(high=df['High'], low=df['Low'], \n",
    "                                                      close=df['Close'], volume=df['Volume']).chaikin_money_flow()\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Volume indicators function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60753445",
   "metadata": {},
   "source": [
    "## 5. Advanced Features Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lagged_features(df, lag_periods=[1, 5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Add lagged returns and prices.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for lag in lag_periods:\n",
    "        df[f'Returns_Lag_{lag}'] = df['Returns'].shift(lag)\n",
    "        df[f'Close_Lag_{lag}'] = df['Close'].shift(lag)\n",
    "        df[f'Volume_Lag_{lag}'] = df['Volume'].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Lagged features function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_statistics(df, windows=[5, 10, 20, 50]):\n",
    "    \"\"\"\n",
    "    Add rolling statistical features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for window in windows:\n",
    "        # Rolling mean and std\n",
    "        df[f'Returns_Mean_{window}'] = df['Returns'].rolling(window=window).mean()\n",
    "        df[f'Returns_Std_{window}'] = df['Returns'].rolling(window=window).std()\n",
    "        \n",
    "        # Rolling skewness and kurtosis\n",
    "        df[f'Returns_Skew_{window}'] = df['Returns'].rolling(window=window).skew()\n",
    "        df[f'Returns_Kurt_{window}'] = df['Returns'].rolling(window=window).kurt()\n",
    "        \n",
    "        # Rolling min and max\n",
    "        df[f'Returns_Min_{window}'] = df['Returns'].rolling(window=window).min()\n",
    "        df[f'Returns_Max_{window}'] = df['Returns'].rolling(window=window).max()\n",
    "        \n",
    "        # Rolling quantiles\n",
    "        df[f'Returns_Q25_{window}'] = df['Returns'].rolling(window=window).quantile(0.25)\n",
    "        df[f'Returns_Q75_{window}'] = df['Returns'].rolling(window=window).quantile(0.75)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Rolling statistics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fourier_features(df, n_components=5):\n",
    "    \"\"\"\n",
    "    Add Fourier features to capture cyclical patterns.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create time index (days since start)\n",
    "    time_idx = np.arange(len(df))\n",
    "    \n",
    "    for i in range(1, n_components + 1):\n",
    "        df[f'Fourier_Sin_{i}'] = np.sin(2 * np.pi * i * time_idx / 252)  # 252 trading days\n",
    "        df[f'Fourier_Cos_{i}'] = np.cos(2 * np.pi * i * time_idx / 252)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Fourier features function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    \"\"\"\n",
    "    Add time-based features (day of week, month, quarter, etc.).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Day of week (0=Monday, 4=Friday)\n",
    "    df['DayOfWeek'] = df.index.dayofweek\n",
    "    \n",
    "    # Month (1-12)\n",
    "    df['Month'] = df.index.month\n",
    "    \n",
    "    # Quarter (1-4)\n",
    "    df['Quarter'] = df.index.quarter\n",
    "    \n",
    "    # Year\n",
    "    df['Year'] = df.index.year\n",
    "    \n",
    "    # Day of month\n",
    "    df['DayOfMonth'] = df.index.day\n",
    "    \n",
    "    # Is month end\n",
    "    df['IsMonthEnd'] = df.index.is_month_end.astype(int)\n",
    "    \n",
    "    # Is quarter end\n",
    "    df['IsQuarterEnd'] = df.index.is_quarter_end.astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Time features function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8130dd",
   "metadata": {},
   "source": [
    "## 6. Apply Feature Engineering to All Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all feature engineering steps\n",
    "print(\"üîß Applying feature engineering to all assets...\\n\")\n",
    "\n",
    "features_data = {}\n",
    "feature_counts = {}\n",
    "\n",
    "for ticker, df in data.items():\n",
    "    print(f\"Processing {ticker}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # Start with original data\n",
    "        df_features = df.copy()\n",
    "        original_cols = len(df_features.columns)\n",
    "        \n",
    "        # Add technical indicators\n",
    "        df_features = add_momentum_indicators(df_features)\n",
    "        df_features = add_trend_indicators(df_features)\n",
    "        df_features = add_volatility_indicators(df_features)\n",
    "        df_features = add_volume_indicators(df_features)\n",
    "        \n",
    "        # Add advanced features\n",
    "        df_features = add_lagged_features(df_features, LAG_PERIODS)\n",
    "        df_features = add_rolling_statistics(df_features, WINDOWS)\n",
    "        df_features = add_fourier_features(df_features, n_components=5)\n",
    "        df_features = add_time_features(df_features)\n",
    "        \n",
    "        # Store result\n",
    "        features_data[ticker] = df_features\n",
    "        new_cols = len(df_features.columns)\n",
    "        feature_counts[ticker] = new_cols - original_cols\n",
    "        \n",
    "        print(f\"‚úÖ Added {new_cols - original_cols} features (Total: {new_cols} columns)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature engineering complete for {len(features_data)} assets\")\n",
    "print(f\"üìä Average features added: {np.mean(list(feature_counts.values())):.0f} per asset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebeba2",
   "metadata": {},
   "source": [
    "## 7. Feature Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc321f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature summary for one asset\n",
    "sample_ticker = 'GSPC'\n",
    "\n",
    "if sample_ticker in features_data:\n",
    "    df_sample = features_data[sample_ticker]\n",
    "    \n",
    "    print(f\"üìä Feature Summary for {sample_ticker}:\\n\")\n",
    "    print(f\"Total features: {len(df_sample.columns)}\")\n",
    "    print(f\"Total rows: {len(df_sample)}\")\n",
    "    print(f\"\\nFeature categories:\")\n",
    "    print(f\"  - Original OHLCV: 5\")\n",
    "    print(f\"  - Basic returns: 5\")\n",
    "    print(f\"  - Momentum indicators: ~10\")\n",
    "    print(f\"  - Trend indicators: ~15\")\n",
    "    print(f\"  - Volatility indicators: ~10\")\n",
    "    print(f\"  - Volume indicators: ~8\")\n",
    "    print(f\"  - Lagged features: {len(LAG_PERIODS) * 3}\")\n",
    "    print(f\"  - Rolling statistics: {len(WINDOWS) * 8}\")\n",
    "    print(f\"  - Fourier features: 10\")\n",
    "    print(f\"  - Time features: 7\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 feature names:\")\n",
    "    for i, col in enumerate(df_sample.columns[:10]):\n",
    "        print(f\"  {i+1}. {col}\")\n",
    "    \n",
    "    print(f\"\\nLast 10 feature names:\")\n",
    "    for i, col in enumerate(df_sample.columns[-10:]):\n",
    "        print(f\"  {len(df_sample.columns)-10+i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values Analysis:\\n\")\n",
    "\n",
    "for ticker, df in features_data.items():\n",
    "    missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "    print(f\"{ticker:10s}: {missing_pct:5.2f}% missing values\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Note: Missing values expected due to rolling windows and lags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7e8ee",
   "metadata": {},
   "source": [
    "## 8. Visualize Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85210cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize technical indicators for S&P 500\n",
    "if 'GSPC' in features_data:\n",
    "    df_viz = features_data['GSPC'].copy()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(18, 14))\n",
    "    \n",
    "    # Price with Bollinger Bands\n",
    "    ax = axes[0]\n",
    "    ax.plot(df_viz.index, df_viz['Close'], label='Close', linewidth=1.5, color='blue')\n",
    "    ax.plot(df_viz.index, df_viz['BB_High'], label='BB High', linewidth=1, linestyle='--', color='red')\n",
    "    ax.plot(df_viz.index, df_viz['BB_Low'], label='BB Low', linewidth=1, linestyle='--', color='green')\n",
    "    ax.plot(df_viz.index, df_viz['BB_Mid'], label='BB Mid', linewidth=1, linestyle='--', color='orange')\n",
    "    ax.set_title('S&P 500 with Bollinger Bands', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Price ($)', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # RSI\n",
    "    ax = axes[1]\n",
    "    ax.plot(df_viz.index, df_viz['RSI_14'], label='RSI (14)', linewidth=1.5, color='purple')\n",
    "    ax.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='Overbought (70)')\n",
    "    ax.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='Oversold (30)')\n",
    "    ax.set_title('Relative Strength Index (RSI)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('RSI', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MACD\n",
    "    ax = axes[2]\n",
    "    ax.plot(df_viz.index, df_viz['MACD'], label='MACD', linewidth=1.5, color='blue')\n",
    "    ax.plot(df_viz.index, df_viz['MACD_Signal'], label='Signal', linewidth=1.5, color='red')\n",
    "    ax.bar(df_viz.index, df_viz['MACD_Diff'], label='Histogram', alpha=0.3, color='gray')\n",
    "    ax.set_title('MACD (Moving Average Convergence Divergence)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('MACD', fontsize=12)\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volume with OBV\n",
    "    ax = axes[3]\n",
    "    ax2 = ax.twinx()\n",
    "    ax.bar(df_viz.index, df_viz['Volume'], alpha=0.3, color='blue', label='Volume')\n",
    "    ax2.plot(df_viz.index, df_viz['OBV'], color='red', linewidth=1.5, label='OBV')\n",
    "    ax.set_title('Volume and On-Balance Volume (OBV)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Volume', fontsize=12, color='blue')\n",
    "    ax2.set_ylabel('OBV', fontsize=12, color='red')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '04_technical_indicators.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Technical indicators visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a5e8d",
   "metadata": {},
   "source": [
    "## 9. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb45c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlations for S&P 500\n",
    "if 'GSPC' in features_data:\n",
    "    df_corr = features_data['GSPC'].copy()\n",
    "    \n",
    "    # Select a subset of important features for visualization\n",
    "    important_features = ['Close', 'Returns', 'RSI_14', 'MACD', 'BB_Width', 'ATR_14', \n",
    "                          'ADX', 'Volume', 'OBV', 'HV_20', 'SMA_20', 'EMA_20']\n",
    "    \n",
    "    # Filter features that exist\n",
    "    available_features = [f for f in important_features if f in df_corr.columns]\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = df_corr[available_features].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, vmin=-1, vmax=1, square=True, ax=ax)\n",
    "    ax.set_title('Feature Correlation Matrix (S&P 500)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, '04_feature_correlations.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Feature correlation visualization saved\")\n",
    "    \n",
    "    # Print highly correlated features\n",
    "    print(\"\\nüîó Highly Correlated Feature Pairs (|corr| > 0.8):\")\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "                print(f\"{corr_matrix.columns[i]:15s} <-> {corr_matrix.columns[j]:15s}: {corr_matrix.iloc[i, j]:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed99214",
   "metadata": {},
   "source": [
    "## 10. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda79371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all engineered features\n",
    "print(\"üíæ Saving engineered features...\\n\")\n",
    "\n",
    "for ticker, df in features_data.items():\n",
    "    filepath = os.path.join(FEATURES_DATA_DIR, f\"{ticker}_features.csv\")\n",
    "    df.to_csv(filepath)\n",
    "    print(f\"‚úÖ {ticker:10s} ‚Üí {filepath}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All features saved to {FEATURES_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60431f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature summary CSV\n",
    "summary_data = []\n",
    "\n",
    "for ticker, df in features_data.items():\n",
    "    summary_data.append({\n",
    "        'Ticker': ticker,\n",
    "        'Total_Features': len(df.columns),\n",
    "        'Total_Rows': len(df),\n",
    "        'Missing_Values': df.isnull().sum().sum(),\n",
    "        'Missing_Pct': (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100,\n",
    "        'Start_Date': df.index.min().strftime('%Y-%m-%d'),\n",
    "        'End_Date': df.index.max().strftime('%Y-%m-%d')\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv(os.path.join(FEATURES_DATA_DIR, '_features_summary.csv'), index=False)\n",
    "\n",
    "print(\"\\nüìä Feature Engineering Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(f\"\\nüíæ Summary saved to {FEATURES_DATA_DIR}/_features_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda9bdc",
   "metadata": {},
   "source": [
    "## 11. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc87d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä FEATURE ENGINEERING - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED TASKS:\")\n",
    "print(\"   1. ‚úÖ Technical indicators (Momentum, Trend, Volatility, Volume)\")\n",
    "print(\"   2. ‚úÖ Lagged features (autoregressive components)\")\n",
    "print(\"   3. ‚úÖ Rolling statistics (mean, std, skew, kurtosis)\")\n",
    "print(\"   4. ‚úÖ Fourier features (cyclical patterns)\")\n",
    "print(\"   5. ‚úÖ Time features (day, month, quarter, etc.)\")\n",
    "\n",
    "print(\"\\nüìÅ FILES GENERATED:\")\n",
    "print(f\"   - {len(features_data)} feature files in {FEATURES_DATA_DIR}/\")\n",
    "print(f\"   - Feature summary: _features_summary.csv\")\n",
    "print(f\"   - Visualizations: 04_technical_indicators.png, 04_feature_correlations.png\")\n",
    "\n",
    "print(\"\\nüìä STATISTICS:\")\n",
    "print(f\"   - Total assets: {len(features_data)}\")\n",
    "print(f\"   - Average features per asset: {np.mean([len(df.columns) for df in features_data.values()]):.0f}\")\n",
    "print(f\"   - Feature categories: 6 (Technical, Lagged, Rolling, Fourier, Time, Original)\")\n",
    "\n",
    "print(\"\\nüîë KEY FEATURES ADDED:\")\n",
    "print(\"   - Momentum: RSI, MACD, Stochastic, ROC, Williams %R\")\n",
    "print(\"   - Trend: SMA, EMA, ADX, Ichimoku\")\n",
    "print(\"   - Volatility: Bollinger Bands, ATR, Keltner Channel, Historical Vol\")\n",
    "print(\"   - Volume: OBV, MFI, CMF, Volume Moving Averages\")\n",
    "print(\"   - Advanced: Lagged returns, Rolling stats, Fourier, Time features\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"   1. Baseline models (ARIMA, LSTM, Prophet)\")\n",
    "print(\"   2. Feature selection and dimensionality reduction\")\n",
    "print(\"   3. Generative model development (TimeGAN, Diffusion)\")\n",
    "print(\"   4. Model training and evaluation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Feature engineering complete! Ready for modeling.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
