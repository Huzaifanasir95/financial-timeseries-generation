{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0e9db2",
   "metadata": {},
   "source": [
    "# TimeGAN: Time Series Generative Adversarial Network\n",
    "## Cryptocurrency Price Prediction using Generative Models\n",
    "\n",
    "This notebook implements TimeGAN (a Generative Adversarial Network for time series) for forecasting cryptocurrency prices. TimeGAN combines autoencoders with GANs to learn realistic temporal dynamics and generate synthetic yet authentic time series data for prediction.\n",
    "\n",
    "**Key Features:**\n",
    "- Embedding Network: Learns compressed representations of time series\n",
    "- Generator Network: Creates synthetic time series samples\n",
    "- Discriminator Network: Distinguishes real from synthetic sequences\n",
    "- Recovery Network: Reconstructs original time series from embeddings\n",
    "- Temporal dynamics learning for realistic forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ CUDA Enabled: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "âœ“ GPU Memory Available: 8.59 GB\n",
      "Device: cuda\n",
      "PyTorch Version: 2.9.1+cu126\n",
      "zaraar malik\n"
     ]
    }
   ],
   "source": [
    "# Note: PyTorch GPU configuration is handled in the comprehensive imports cell below\n",
    "# This prevents redundant initialization and ensures all configuration is centralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9d6a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ CUDA Not Available - Using CPU\n",
      "âœ“ Device: cpu\n",
      "âœ“ PyTorch Version: 2.8.0+cpu\n",
      "âœ“ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Metrics for evaluation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# ==================== DEVICE CONFIGURATION ====================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8)  # Allocate 80% of GPU memory\n",
    "    print(f\"âœ“ CUDA Enabled: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ“ GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ CUDA Not Available - Using CPU\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(f\"âœ“ Device: {device}\")\n",
    "print(f\"âœ“ PyTorch Version: {torch.__version__}\")\n",
    "print(\"âœ“ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f501db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GPU DIAGNOSTICS & CONFIGURATION (PYTORCH)\n",
      "================================================================================\n",
      "\n",
      "1. PyTorch CUDA Devices:\n",
      "   CUDA Available: False\n",
      "   Number of GPUs: 0\n",
      "   âš ï¸  GPU NOT DETECTED\n",
      "      â€¢ Your system doesn't have a NVIDIA GPU, OR\n",
      "      â€¢ CUDA/cuDNN not installed, OR\n",
      "      â€¢ GPU drivers not compatible\n",
      "\n",
      "      Solution: CPU training will proceed normally but slower.\n",
      "      For GPU support, install:\n",
      "      - NVIDIA GPU (RTX 3060+, RTX 4060+, etc.)\n",
      "      - CUDA Toolkit matching PyTorch version\n",
      "      - cuDNN library\n",
      "\n",
      "4. Device Configuration:\n",
      "   Current Device: cpu\n",
      "   Device Type: CPU\n",
      "\n",
      "5. Training Configuration:\n",
      "   CPU mode activated - training will be slower\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# PyTorch GPU Diagnostics and Configuration\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GPU DIAGNOSTICS & CONFIGURATION (PYTORCH)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. PyTorch CUDA Devices:\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"   CUDA Available: {cuda_available}\")\n",
    "print(f\"   Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if cuda_available:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\n2. GPU {i} Details:\")\n",
    "        print(f\"   Name: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"   Total Memory: {props.total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"   Major Capability: {props.major}\")\n",
    "        print(f\"   Minor Capability: {props.minor}\")\n",
    "        \n",
    "        print(f\"\\n3. Current GPU {i} Memory Usage:\")\n",
    "        print(f\"   Allocated: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n",
    "        print(f\"   Reserved: {torch.cuda.memory_reserved(i) / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"   âš ï¸  GPU NOT DETECTED\")\n",
    "    print(\"      â€¢ Your system doesn't have a NVIDIA GPU, OR\")\n",
    "    print(\"      â€¢ CUDA/cuDNN not installed, OR\")\n",
    "    print(\"      â€¢ GPU drivers not compatible\")\n",
    "    print(\"\\n      Solution: CPU training will proceed normally but slower.\")\n",
    "    print(\"      For GPU support, install:\")\n",
    "    print(\"      - NVIDIA GPU (RTX 3060+, RTX 4060+, etc.)\")\n",
    "    print(\"      - CUDA Toolkit matching PyTorch version\")\n",
    "    print(\"      - cuDNN library\")\n",
    "\n",
    "print(f\"\\n4. Device Configuration:\")\n",
    "print(f\"   Current Device: {device}\")\n",
    "print(f\"   Device Type: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "print(f\"\\n5. Training Configuration:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   âœ“ GPU ENABLED: {torch.cuda.device_count()} GPU(s) detected\")\n",
    "    print(\"   âœ“ CUDA Memory Growth: Enabled (dynamic allocation)\")\n",
    "    print(\"   âœ“ PyTorch will automatically use GPU for tensor operations\")\n",
    "    print(\"   âœ“ Expected speedup: 5-10x faster than CPU\")\n",
    "else:\n",
    "    print(\"   CPU mode activated - training will be slower\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc79641",
   "metadata": {},
   "source": [
    "## Section 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed5ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA LOADED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "BTC_USD:\n",
      "  Training samples: 3103\n",
      "  Test samples: 548\n",
      "  Date range: 2015-01-02 to 2024-12-30\n",
      "\n",
      "ETH_USD:\n",
      "  Training samples: 2216\n",
      "  Test samples: 392\n",
      "  Date range: 2017-11-10 to 2024-12-30\n",
      "\n",
      "BNB_USD:\n",
      "  Training samples: 2216\n",
      "  Test samples: 392\n",
      "  Date range: 2017-11-10 to 2024-12-30\n",
      "\n",
      "ADA_USD:\n",
      "  Training samples: 2216\n",
      "  Test samples: 392\n",
      "  Date range: 2017-11-10 to 2024-12-30\n",
      "\n",
      "SOL_USD:\n",
      "  Training samples: 1466\n",
      "  Test samples: 259\n",
      "  Date range: 2020-04-11 to 2024-12-30\n"
     ]
    }
   ],
   "source": [
    "# Load Cryptocurrency Data\n",
    "def load_crypto_data_timegan():\n",
    "    \"\"\"Load cryptocurrency data from train, val, and test directories\"\"\"\n",
    "    cryptos = ['BTC_USD', 'ETH_USD', 'BNB_USD', 'ADA_USD', 'SOL_USD']\n",
    "    data = {}\n",
    "    \n",
    "    for crypto in cryptos:\n",
    "        train_df = pd.read_csv(f'data/train/{crypto}_train.csv')\n",
    "        val_df = pd.read_csv(f'data/val/{crypto}_val.csv')\n",
    "        test_df = pd.read_csv(f'data/test/{crypto}_test.csv')\n",
    "        \n",
    "        # Ensure Date column is datetime\n",
    "        train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
    "        val_df['Date'] = pd.to_datetime(val_df['Date'])\n",
    "        test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "        \n",
    "        # Combine train and val for training\n",
    "        combined = pd.concat([train_df, val_df], ignore_index=True)\n",
    "        combined = combined.sort_values('Date').reset_index(drop=True)\n",
    "        \n",
    "        data[crypto] = {\n",
    "            'train': combined,\n",
    "            'test': test_df.sort_values('Date').reset_index(drop=True),\n",
    "            'train_size': len(combined),\n",
    "            'test_size': len(test_df)\n",
    "        }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "crypto_data_timegan = load_crypto_data_timegan()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for crypto, info in crypto_data_timegan.items():\n",
    "    print(f\"\\n{crypto}:\")\n",
    "    print(f\"  Training samples: {info['train_size']}\")\n",
    "    print(f\"  Test samples: {info['test_size']}\")\n",
    "    print(f\"  Date range: {info['train'].iloc[0]['Date'].date()} to {info['test'].iloc[-1]['Date'].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321af89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING DATA FOR TIMEGAN\n",
      "================================================================================\n",
      "\n",
      "BTC_USD:\n",
      "  Training sequences shape: (3073, 30)\n",
      "  Sequence length: 30\n",
      "  Test samples: 548\n",
      "\n",
      "ETH_USD:\n",
      "  Training sequences shape: (2186, 30)\n",
      "  Sequence length: 30\n",
      "  Test samples: 392\n",
      "\n",
      "BNB_USD:\n",
      "  Training sequences shape: (2186, 30)\n",
      "  Sequence length: 30\n",
      "  Test samples: 392\n",
      "\n",
      "ADA_USD:\n",
      "  Training sequences shape: (2186, 30)\n",
      "  Sequence length: 30\n",
      "  Test samples: 392\n",
      "\n",
      "SOL_USD:\n",
      "  Training sequences shape: (1436, 30)\n",
      "  Sequence length: 30\n",
      "  Test samples: 259\n",
      "\n",
      "âœ“ Data prepared successfully for TimeGAN!\n"
     ]
    }
   ],
   "source": [
    "# Create Sequences for TimeGAN\n",
    "def create_sequences(data, seq_length=30):\n",
    "    \"\"\"\n",
    "    Create sequences of fixed length from time series data\n",
    "    \n",
    "    Parameters:\n",
    "    - data: 1D array of values\n",
    "    - seq_length: Length of each sequence\n",
    "    \n",
    "    Returns:\n",
    "    - 2D array of sequences (n_sequences, seq_length)\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"Normalize data using MinMaxScaler\"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data.reshape(-1, 1))\n",
    "    return scaled_data.flatten(), scaler\n",
    "\n",
    "# Prepare data for all cryptocurrencies\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPARING DATA FOR TIMEGAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timegan_data = {}\n",
    "seq_length = 30\n",
    "\n",
    "for crypto, info in crypto_data_timegan.items():\n",
    "    # Get Close prices\n",
    "    train_prices = info['train']['Close'].values\n",
    "    test_prices = info['test']['Close'].values\n",
    "    \n",
    "    # Normalize training data\n",
    "    train_normalized, train_scaler = normalize_data(train_prices)\n",
    "    \n",
    "    # Create sequences\n",
    "    train_sequences = create_sequences(train_normalized, seq_length)\n",
    "    \n",
    "    timegan_data[crypto] = {\n",
    "        'train_sequences': train_sequences,\n",
    "        'test_prices': test_prices,\n",
    "        'train_prices': train_prices,\n",
    "        'train_scaler': train_scaler,\n",
    "        'train_normalized': train_normalized\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{crypto}:\")\n",
    "    print(f\"  Training sequences shape: {train_sequences.shape}\")\n",
    "    print(f\"  Sequence length: {seq_length}\")\n",
    "    print(f\"  Test samples: {len(test_prices)}\")\n",
    "\n",
    "print(\"\\nâœ“ Data prepared successfully for TimeGAN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe74347",
   "metadata": {},
   "source": [
    "## Section 2: Build TimeGAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293104fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BUILDING TIMEGAN ARCHITECTURE (PYTORCH)\n",
      "================================================================================\n",
      "\n",
      "Building TimeGAN for BTC_USD...\n",
      "âœ“ TimeGAN architecture built successfully\n",
      "\n",
      "Building TimeGAN for ETH_USD...\n",
      "âœ“ TimeGAN architecture built successfully\n",
      "\n",
      "Building TimeGAN for BNB_USD...\n",
      "âœ“ TimeGAN architecture built successfully\n",
      "\n",
      "Building TimeGAN for ADA_USD...\n",
      "âœ“ TimeGAN architecture built successfully\n",
      "\n",
      "Building TimeGAN for SOL_USD...\n",
      "âœ“ TimeGAN architecture built successfully\n",
      "\n",
      "================================================================================\n",
      "All TimeGAN models built successfully and moved to device!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Build TimeGAN Components (PyTorch)\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    \"\"\"Embedding Network (Encoder) for TimeGAN\"\"\"\n",
    "    def __init__(self, seq_length, n_features=1, latent_dim=10, hidden_dim=32):\n",
    "        super(EmbeddingNetwork, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(n_features, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.dense = nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Take last output\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "class RecoveryNetwork(nn.Module):\n",
    "    \"\"\"Recovery Network (Decoder) for TimeGAN\"\"\"\n",
    "    def __init__(self, seq_length, n_features=1, latent_dim=10, hidden_dim=32):\n",
    "        super(RecoveryNetwork, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.dense = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.dense_out = nn.Linear(hidden_dim, n_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = x.unsqueeze(1).repeat(1, self.seq_length, 1)  # Repeat for sequence length\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dense_out(x)\n",
    "        return x\n",
    "\n",
    "class GeneratorNetwork(nn.Module):\n",
    "    \"\"\"Generator Network for TimeGAN\"\"\"\n",
    "    def __init__(self, seq_length, n_features=1, latent_dim=10, hidden_dim=32):\n",
    "        super(GeneratorNetwork, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.dense = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.dense_out = nn.Linear(hidden_dim, n_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = x.unsqueeze(1).repeat(1, self.seq_length, 1)  # Repeat for sequence length\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dense_out(x)\n",
    "        return x\n",
    "\n",
    "class DiscriminatorNetwork(nn.Module):\n",
    "    \"\"\"Discriminator Network for TimeGAN\"\"\"\n",
    "    def __init__(self, seq_length, n_features=1, hidden_dim=32):\n",
    "        super(DiscriminatorNetwork, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(n_features, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, dropout=0.2)\n",
    "        self.dense = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Take last output\n",
    "        x = self.dense(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class TimeGAN(nn.Module):\n",
    "    \"\"\"\n",
    "    TimeGAN: Generative Adversarial Network for Time Series (PyTorch Implementation)\n",
    "    \n",
    "    Components:\n",
    "    - Embedding Network: Compresses time series into latent space\n",
    "    - Generator Network: Generates synthetic time series from noise\n",
    "    - Recovery Network: Reconstructs time series from embeddings\n",
    "    - Discriminator Network: Distinguishes real from synthetic sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seq_length, n_features=1, latent_dim=10, hidden_dim=32):\n",
    "        \"\"\"\n",
    "        Initialize TimeGAN\n",
    "        \n",
    "        Parameters:\n",
    "        - seq_length: Length of time series sequences\n",
    "        - n_features: Number of features (default: 1 for univariate)\n",
    "        - latent_dim: Dimension of latent space\n",
    "        - hidden_dim: Hidden layer dimension\n",
    "        \"\"\"\n",
    "        super(TimeGAN, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.n_features = n_features\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Build network components\n",
    "        self.embedding = EmbeddingNetwork(seq_length, n_features, latent_dim, hidden_dim)\n",
    "        self.recovery = RecoveryNetwork(seq_length, n_features, latent_dim, hidden_dim)\n",
    "        self.generator = GeneratorNetwork(seq_length, n_features, latent_dim, hidden_dim)\n",
    "        self.discriminator = DiscriminatorNetwork(seq_length, n_features, hidden_dim)\n",
    "        \n",
    "        print(\"âœ“ TimeGAN architecture built successfully\")\n",
    "    \n",
    "    def get_embeddings(self, sequences):\n",
    "        \"\"\"Get embeddings for sequences\"\"\"\n",
    "        return self.embedding(sequences)\n",
    "    \n",
    "    def generate_samples(self, noise):\n",
    "        \"\"\"Generate synthetic sequences from noise\"\"\"\n",
    "        return self.generator(noise)\n",
    "    \n",
    "    def discriminate(self, sequences):\n",
    "        \"\"\"Discriminate real vs synthetic sequences\"\"\"\n",
    "        return self.discriminator(sequences)\n",
    "\n",
    "# Build TimeGAN for each cryptocurrency\n",
    "print(\"=\" * 80)\n",
    "print(\"BUILDING TIMEGAN ARCHITECTURE (PYTORCH)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timegan_models = {}\n",
    "for crypto in timegan_data.keys():\n",
    "    print(f\"\\nBuilding TimeGAN for {crypto}...\")\n",
    "    model = TimeGAN(seq_length=seq_length, n_features=1, latent_dim=10, hidden_dim=32)\n",
    "    model = model.to(device)  # Move model to GPU/CPU\n",
    "    timegan_models[crypto] = model\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All TimeGAN models built successfully and moved to device!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5a68d",
   "metadata": {},
   "source": [
    "## Section 3: Train TimeGAN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING TIMEGAN MODELS (PYTORCH GPU ACCELERATION)\n",
      "================================================================================\n",
      "Device: cpu\n",
      "âš ï¸  GPU Acceleration: DISABLED (CPU mode)\n",
      "âœ“ Epochs: 50 (Full training)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Training TimeGAN for BTC_USD...\n",
      "================================================================================\n",
      "Training will use: CPU\n",
      "Training will use: CPU\n",
      "Epoch 5/50 - Embedding Loss: 0.0009, Generator Loss: 0.6842, Discriminator Loss: 1.3862\n",
      "Epoch 5/50 - Embedding Loss: 0.0009, Generator Loss: 0.6842, Discriminator Loss: 1.3862\n",
      "Epoch 10/50 - Embedding Loss: 0.0008, Generator Loss: 0.7572, Discriminator Loss: 1.2330\n",
      "Epoch 10/50 - Embedding Loss: 0.0008, Generator Loss: 0.7572, Discriminator Loss: 1.2330\n",
      "Epoch 15/50 - Embedding Loss: 0.0008, Generator Loss: 0.7722, Discriminator Loss: 1.3304\n",
      "Epoch 15/50 - Embedding Loss: 0.0008, Generator Loss: 0.7722, Discriminator Loss: 1.3304\n",
      "Epoch 20/50 - Embedding Loss: 0.0008, Generator Loss: 0.6457, Discriminator Loss: 1.4576\n",
      "Epoch 20/50 - Embedding Loss: 0.0008, Generator Loss: 0.6457, Discriminator Loss: 1.4576\n",
      "Epoch 25/50 - Embedding Loss: 0.0008, Generator Loss: 0.7120, Discriminator Loss: 1.3661\n",
      "Epoch 25/50 - Embedding Loss: 0.0008, Generator Loss: 0.7120, Discriminator Loss: 1.3661\n",
      "Epoch 30/50 - Embedding Loss: 0.0008, Generator Loss: 0.6896, Discriminator Loss: 1.3953\n",
      "Epoch 30/50 - Embedding Loss: 0.0008, Generator Loss: 0.6896, Discriminator Loss: 1.3953\n",
      "Epoch 35/50 - Embedding Loss: 0.0008, Generator Loss: 0.6927, Discriminator Loss: 1.3864\n",
      "Epoch 35/50 - Embedding Loss: 0.0008, Generator Loss: 0.6927, Discriminator Loss: 1.3864\n",
      "Epoch 40/50 - Embedding Loss: 0.0008, Generator Loss: 0.6932, Discriminator Loss: 1.3858\n",
      "Epoch 40/50 - Embedding Loss: 0.0008, Generator Loss: 0.6932, Discriminator Loss: 1.3858\n",
      "Epoch 45/50 - Embedding Loss: 0.0007, Generator Loss: 0.6933, Discriminator Loss: 1.3857\n",
      "Epoch 45/50 - Embedding Loss: 0.0007, Generator Loss: 0.6933, Discriminator Loss: 1.3857\n",
      "Epoch 50/50 - Embedding Loss: 0.0008, Generator Loss: 0.6931, Discriminator Loss: 1.3862\n",
      "âœ“ BTC_USD training completed\n",
      "\n",
      "================================================================================\n",
      "Training TimeGAN for ETH_USD...\n",
      "================================================================================\n",
      "Training will use: CPU\n",
      "Epoch 50/50 - Embedding Loss: 0.0008, Generator Loss: 0.6931, Discriminator Loss: 1.3862\n",
      "âœ“ BTC_USD training completed\n",
      "\n",
      "================================================================================\n",
      "Training TimeGAN for ETH_USD...\n",
      "================================================================================\n",
      "Training will use: CPU\n",
      "Epoch 5/50 - Embedding Loss: 0.0015, Generator Loss: 1.0307, Discriminator Loss: 1.2976\n",
      "Epoch 5/50 - Embedding Loss: 0.0015, Generator Loss: 1.0307, Discriminator Loss: 1.2976\n",
      "Epoch 10/50 - Embedding Loss: 0.0014, Generator Loss: 0.7570, Discriminator Loss: 1.2989\n",
      "Epoch 10/50 - Embedding Loss: 0.0014, Generator Loss: 0.7570, Discriminator Loss: 1.2989\n",
      "Epoch 15/50 - Embedding Loss: 0.0013, Generator Loss: 0.7966, Discriminator Loss: 1.2644\n",
      "Epoch 15/50 - Embedding Loss: 0.0013, Generator Loss: 0.7966, Discriminator Loss: 1.2644\n",
      "Epoch 20/50 - Embedding Loss: 0.0012, Generator Loss: 0.7883, Discriminator Loss: 1.2652\n",
      "Epoch 20/50 - Embedding Loss: 0.0012, Generator Loss: 0.7883, Discriminator Loss: 1.2652\n",
      "Epoch 25/50 - Embedding Loss: 0.0012, Generator Loss: 0.7867, Discriminator Loss: 1.2639\n",
      "Epoch 25/50 - Embedding Loss: 0.0012, Generator Loss: 0.7867, Discriminator Loss: 1.2639\n",
      "Epoch 30/50 - Embedding Loss: 0.0012, Generator Loss: 0.7883, Discriminator Loss: 1.2630\n",
      "Epoch 30/50 - Embedding Loss: 0.0012, Generator Loss: 0.7883, Discriminator Loss: 1.2630\n"
     ]
    }
   ],
   "source": [
    "# Train TimeGAN (PyTorch with GPU Acceleration)\n",
    "def train_timegan(timegan, train_sequences, device, epochs=50, batch_size=64, verbose=False):\n",
    "    \"\"\"\n",
    "    Train TimeGAN with combined losses (PyTorch with GPU)\n",
    "    \n",
    "    Parameters:\n",
    "    - timegan: TimeGAN model\n",
    "    - train_sequences: Training sequences\n",
    "    - device: Device to use (GPU or CPU)\n",
    "    - epochs: Number of training epochs\n",
    "    - batch_size: Batch size for training\n",
    "    - verbose: Print training progress\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loss functions\n",
    "    mse_loss = nn.MSELoss()\n",
    "    bce_loss = nn.BCELoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    embedding_opt = optim.Adam(\n",
    "        list(timegan.embedding.parameters()) + list(timegan.recovery.parameters()),\n",
    "        lr=0.001\n",
    "    )\n",
    "    generator_opt = optim.Adam(timegan.generator.parameters(), lr=0.001)\n",
    "    discriminator_opt = optim.Adam(timegan.discriminator.parameters(), lr=0.001)\n",
    "    \n",
    "    history = {'embedding_loss': [], 'generator_loss': [], 'discriminator_loss': []}\n",
    "    \n",
    "    # Convert sequences to tensor with proper shape (N, seq_len, 1)\n",
    "    train_tensor = torch.FloatTensor(train_sequences).unsqueeze(2).to(device)  # (N, seq_len, 1)\n",
    "    \n",
    "    device_type = 'GPU' if torch.cuda.is_available() else 'CPU'\n",
    "    print(f\"Training will use: {device_type}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_embedding_loss = 0\n",
    "        epoch_generator_loss = 0\n",
    "        epoch_discriminator_loss = 0\n",
    "        \n",
    "        # Shuffle training data\n",
    "        indices = torch.randperm(len(train_tensor))\n",
    "        n_batches = 0\n",
    "        \n",
    "        for idx in range(0, len(train_tensor), batch_size):\n",
    "            batch_indices = indices[idx:idx + batch_size]\n",
    "            real_sequences = train_tensor[batch_indices]  # Already on device (batch, seq_len, 1)\n",
    "            batch_size_actual = len(batch_indices)\n",
    "            \n",
    "            # ==================== Embedding Network Training ====================\n",
    "            timegan.embedding.train()\n",
    "            timegan.recovery.train()\n",
    "            \n",
    "            embeddings = timegan.embedding(real_sequences)\n",
    "            reconstructed = timegan.recovery(embeddings)\n",
    "            \n",
    "            embedding_loss = mse_loss(real_sequences, reconstructed)\n",
    "            \n",
    "            embedding_opt.zero_grad()\n",
    "            embedding_loss.backward()\n",
    "            embedding_opt.step()\n",
    "            \n",
    "            # ==================== Generator Training ====================\n",
    "            timegan.generator.train()\n",
    "            timegan.discriminator.train()\n",
    "            \n",
    "            noise = torch.randn(batch_size_actual, timegan.latent_dim).to(device)\n",
    "            synthetic_sequences = timegan.generator(noise)\n",
    "            discriminator_output = timegan.discriminator(synthetic_sequences)\n",
    "            \n",
    "            generator_loss = bce_loss(discriminator_output, torch.ones_like(discriminator_output))\n",
    "            \n",
    "            generator_opt.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            generator_opt.step()\n",
    "            \n",
    "            # ==================== Discriminator Training ====================\n",
    "            timegan.discriminator.train()\n",
    "            \n",
    "            real_output = timegan.discriminator(real_sequences)\n",
    "            synthetic_output = timegan.discriminator(synthetic_sequences.detach())\n",
    "            \n",
    "            real_loss = bce_loss(real_output, torch.ones_like(real_output))\n",
    "            synthetic_loss = bce_loss(synthetic_output, torch.zeros_like(synthetic_output))\n",
    "            discriminator_loss = real_loss + synthetic_loss\n",
    "            \n",
    "            discriminator_opt.zero_grad()\n",
    "            discriminator_loss.backward()\n",
    "            discriminator_opt.step()\n",
    "            \n",
    "            epoch_embedding_loss += embedding_loss.item()\n",
    "            epoch_generator_loss += generator_loss.item()\n",
    "            epoch_discriminator_loss += discriminator_loss.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        # Average losses\n",
    "        history['embedding_loss'].append(epoch_embedding_loss / n_batches)\n",
    "        history['generator_loss'].append(epoch_generator_loss / n_batches)\n",
    "        history['discriminator_loss'].append(epoch_discriminator_loss / n_batches)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs} - \" +\n",
    "                  f\"Embedding Loss: {history['embedding_loss'][-1]:.4f}, \" +\n",
    "                  f\"Generator Loss: {history['generator_loss'][-1]:.4f}, \" +\n",
    "                  f\"Discriminator Loss: {history['discriminator_loss'][-1]:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train TimeGAN for all cryptocurrencies\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING TIMEGAN MODELS (PYTORCH GPU ACCELERATION)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU Acceleration: ENABLED ({torch.cuda.device_count()} GPU detected)\")\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ“ All training operations will run on GPU\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU Acceleration: DISABLED (CPU mode)\")\n",
    "print(f\"âœ“ Epochs: 50 (Full training)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timegan_histories = {}\n",
    "for crypto in timegan_models.keys():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training TimeGAN for {crypto}...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    train_sequences = timegan_data[crypto]['train_sequences']\n",
    "    \n",
    "    # 50 epochs with batch size 32 (matching other models)\n",
    "    history = train_timegan(timegan_models[crypto], train_sequences, device,\n",
    "                           epochs=50, batch_size=32, verbose=True)\n",
    "    timegan_histories[crypto] = history\n",
    "    \n",
    "    print(f\"âœ“ {crypto} training completed\")\n",
    "    \n",
    "    # Clear GPU cache after each model training\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All TimeGAN models trained successfully with GPU acceleration!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bfe0b",
   "metadata": {},
   "source": [
    "## Section 4: Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING PREDICTIONS (PYTORCH)\n",
      "================================================================================\n",
      "\n",
      "Generating predictions for BTC_USD...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m test_size \u001b[38;5;241m=\u001b[39m timegan_data[crypto][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_prices\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Generate normalized predictions on GPU\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m normalized_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_timegan_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimegan_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcrypto\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Denormalize predictions\u001b[39;00m\n\u001b[0;32m     66\u001b[0m scaler \u001b[38;5;241m=\u001b[39m timegan_data[crypto][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_scaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[15], line 39\u001b[0m, in \u001b[0;36mgenerate_timegan_predictions\u001b[1;34m(timegan, train_sequences, test_size, seq_length, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# Update sequence (shift and add new prediction)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;66;03m# Shift: remove first element, append new prediction\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m         new_seq \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         current_sequence \u001b[38;5;241m=\u001b[39m new_seq\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "# Generate Predictions using TimeGAN (PyTorch) - IMPROVED PREDICTION STRATEGY\n",
    "def generate_timegan_predictions(timegan, train_sequences, test_size, seq_length, device):\n",
    "    \"\"\"\n",
    "    Generate predictions for test period using trained TimeGAN\n",
    "    \n",
    "    IMPROVED STRATEGY: Instead of autoregressive prediction with recovery network,\n",
    "    we use the trained embedding to extract features, then predict using\n",
    "    a simpler approach based on the last sequence's trend.\n",
    "    \n",
    "    Parameters:\n",
    "    - timegan: Trained TimeGAN model\n",
    "    - train_sequences: Training sequences (for context)\n",
    "    - test_size: Number of test samples to predict\n",
    "    - seq_length: Sequence length\n",
    "    - device: Device to use (GPU or CPU)\n",
    "    \n",
    "    Returns:\n",
    "    - Array of predictions\n",
    "    \"\"\"\n",
    "    print(\"âœ“ Using IMPROVED prediction strategy (embedding-based trend extrapolation)\")\n",
    "    timegan.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    # Start with last training sequence\n",
    "    if len(train_sequences) > 0:\n",
    "        current_sequence = torch.FloatTensor(train_sequences[-1]).reshape(1, seq_length, 1).to(device)\n",
    "    else:\n",
    "        current_sequence = torch.randn(1, seq_length, 1).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get initial embedding to understand the pattern\n",
    "        embedding = timegan.get_embeddings(current_sequence)\n",
    "        \n",
    "        # Use generator to create synthetic continuation (better for forecasting)\n",
    "        # Generator learns to create realistic sequences from latent space\n",
    "        generated_sequence = timegan.generate_samples(embedding)\n",
    "        \n",
    "        # Extract predictions from generated sequence\n",
    "        # Use the trend from generated sequence for predictions\n",
    "        generated_values = generated_sequence[0, :, 0].cpu().numpy()\n",
    "        \n",
    "        # Calculate trend from last known sequence\n",
    "        last_values = current_sequence[0, :, 0].cpu().numpy()\n",
    "        trend = (last_values[-1] - last_values[0]) / len(last_values)\n",
    "        \n",
    "        # Generate predictions using combination of generated pattern and trend\n",
    "        for i in range(test_size):\n",
    "            if i < len(generated_values):\n",
    "                # Use generated values with trend adjustment\n",
    "                pred = generated_values[i] + (trend * (i + 1) * 0.1)  # Dampen trend influence\n",
    "            else:\n",
    "                # For longer horizons, use last prediction + small trend\n",
    "                pred = predictions[-1] + trend * 0.05\n",
    "            \n",
    "            # Clip to valid range [0, 1] since data is normalized\n",
    "            pred = np.clip(pred, 0, 1)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update for next iteration if needed\n",
    "            if (i + 1) % seq_length == 0 and i + 1 < test_size:\n",
    "                # Create new sequence from recent predictions\n",
    "                recent_preds = predictions[-seq_length:]\n",
    "                current_sequence = torch.FloatTensor(recent_preds).reshape(1, seq_length, 1).to(device)\n",
    "                embedding = timegan.get_embeddings(current_sequence)\n",
    "                generated_sequence = timegan.generate_samples(embedding)\n",
    "                generated_values = generated_sequence[0, :, 0].cpu().numpy()\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Generate predictions for all cryptocurrencies\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATING PREDICTIONS (PYTORCH)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timegan_predictions = {}\n",
    "for crypto in timegan_models.keys():\n",
    "    print(f\"\\nGenerating predictions for {crypto}...\")\n",
    "    \n",
    "    train_sequences = timegan_data[crypto]['train_sequences']\n",
    "    test_size = timegan_data[crypto]['test_prices'].shape[0]\n",
    "    \n",
    "    # Generate normalized predictions on GPU\n",
    "    normalized_predictions = generate_timegan_predictions(\n",
    "        timegan_models[crypto], \n",
    "        train_sequences, \n",
    "        test_size, \n",
    "        seq_length,\n",
    "        device\n",
    "    )\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    scaler = timegan_data[crypto]['train_scaler']\n",
    "    predictions = scaler.inverse_transform(normalized_predictions.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    timegan_predictions[crypto] = predictions\n",
    "    \n",
    "    print(f\"âœ“ Generated {len(predictions)} predictions for {crypto}\")\n",
    "    print(f\"  Mean prediction: ${predictions.mean():.2f}\")\n",
    "    print(f\"  Min prediction: ${predictions.min():.2f}\")\n",
    "    print(f\"  Max prediction: ${predictions.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5eaaa3",
   "metadata": {},
   "source": [
    "## Section 5: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate TimeGAN Models\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "timegan_metrics = {}\n",
    "results_data = []\n",
    "\n",
    "for crypto in timegan_predictions.keys():\n",
    "    predictions = timegan_predictions[crypto]\n",
    "    actual_prices = timegan_data[crypto]['test_prices']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual_prices, predictions))\n",
    "    mae = mean_absolute_error(actual_prices, predictions)\n",
    "    mape = np.mean(np.abs((actual_prices - predictions) / actual_prices)) * 100\n",
    "    r2 = r2_score(actual_prices, predictions)\n",
    "    \n",
    "    timegan_metrics[crypto] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'RÂ²': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{crypto}:\")\n",
    "    print(f\"  RMSE: ${rmse:.2f}\")\n",
    "    print(f\"  MAE:  ${mae:.2f}\")\n",
    "    print(f\"  MAPE: {mape:.4f}%\")\n",
    "    print(f\"  RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    results_data.append({\n",
    "        'Cryptocurrency': crypto,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'RÂ² Score': r2\n",
    "    })\n",
    "\n",
    "# Create results dataframe\n",
    "timegan_results_df = pd.DataFrame(results_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TIMEGAN PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(timegan_results_df.to_string(index=False))\n",
    "\n",
    "# Find best models\n",
    "best_r2_idx = timegan_results_df['RÂ² Score'].idxmax()\n",
    "best_rmse_idx = timegan_results_df['RMSE'].idxmin()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BEST PERFORMERS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"ðŸ† Best RÂ² Score: {timegan_results_df.iloc[best_r2_idx]['Cryptocurrency']} ({timegan_results_df.iloc[best_r2_idx]['RÂ² Score']:.4f})\")\n",
    "print(f\"ðŸ† Best RMSE: {timegan_results_df.iloc[best_rmse_idx]['Cryptocurrency']} (${timegan_results_df.iloc[best_rmse_idx]['RMSE']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e333f2",
   "metadata": {},
   "source": [
    "## Section 6: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f12efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TimeGAN Predictions\n",
    "fig, axes = plt.subplots(5, 1, figsize=(16, 18))\n",
    "fig.suptitle('TimeGAN Model: Predictions vs Actual Prices', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "cryptos = list(timegan_predictions.keys())\n",
    "for idx, crypto in enumerate(cryptos):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    predictions = timegan_predictions[crypto]\n",
    "    actual_prices = timegan_data[crypto]['test_prices']\n",
    "    dates = crypto_data_timegan[crypto]['test']['Date'].values\n",
    "    \n",
    "    # Plot actual prices\n",
    "    ax.plot(dates, actual_prices, 'b-', label='Actual Price', linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    # Plot predicted prices\n",
    "    ax.plot(dates, predictions, 'r--', label='TimeGAN Prediction', linewidth=2, marker='s', markersize=3)\n",
    "    \n",
    "    # Get metrics for title\n",
    "    metrics = timegan_metrics[crypto]\n",
    "    \n",
    "    ax.set_title(f'{crypto} - RÂ² Score: {metrics[\"RÂ²\"]:.4f}, RMSE: ${metrics[\"RMSE\"]:.2f}, MAE: ${metrics[\"MAE\"]:.2f}', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=10)\n",
    "    ax.set_ylabel('Price (USD)', fontsize=10)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('timegan_predictions.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Prediction visualization saved as 'timegan_predictions.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Loss\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('TimeGAN Training Loss Components', fontsize=14, fontweight='bold')\n",
    "\n",
    "cryptos = list(timegan_histories.keys())\n",
    "\n",
    "for loss_type_idx, loss_type in enumerate(['embedding_loss', 'generator_loss', 'discriminator_loss']):\n",
    "    ax = axes[loss_type_idx]\n",
    "    \n",
    "    for crypto in cryptos:\n",
    "        history = timegan_histories[crypto]\n",
    "        ax.plot(history[loss_type], label=crypto, linewidth=2, marker='o', markersize=3)\n",
    "    \n",
    "    ax.set_title(f'{loss_type.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=10)\n",
    "    ax.set_ylabel('Loss', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('timegan_training_losses.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Training loss visualization saved as 'timegan_training_losses.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d5ee8",
   "metadata": {},
   "source": [
    "## Section 7: Export Predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94973b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export TimeGAN Predictions to CSV\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'TimeGAN_Model_Predictions'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING TIMEGAN PREDICTIONS TO CSV\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for crypto in timegan_predictions.keys():\n",
    "    predictions = timegan_predictions[crypto]\n",
    "    actual_prices = timegan_data[crypto]['test_prices']\n",
    "    dates = crypto_data_timegan[crypto]['test']['Date'].values\n",
    "    \n",
    "    # Create export dataframe\n",
    "    export_df = pd.DataFrame()\n",
    "    export_df['Date'] = dates\n",
    "    export_df['Actual_Price'] = actual_prices\n",
    "    export_df['Predicted_Price'] = predictions\n",
    "    \n",
    "    # Calculate errors\n",
    "    export_df['Absolute_Error'] = np.abs(export_df['Actual_Price'] - export_df['Predicted_Price'])\n",
    "    export_df['Percentage_Error'] = (export_df['Absolute_Error'] / export_df['Actual_Price']) * 100\n",
    "    \n",
    "    # Get metrics\n",
    "    metrics = timegan_metrics[crypto]\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_filename = f'{output_dir}/timegan_model_predictions_{crypto.lower()}.csv'\n",
    "    export_df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved {crypto}: {csv_filename}\")\n",
    "    print(f\"  Rows: {len(export_df)}\")\n",
    "    print(f\"  RÂ² Score: {metrics['RÂ²']:.4f}\")\n",
    "    print(f\"  RMSE: ${metrics['RMSE']:.2f}\")\n",
    "    print(f\"  MAE: ${metrics['MAE']:.2f}\")\n",
    "    print(f\"  MAPE: {metrics['MAPE']:.4f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All TimeGAN predictions saved to 'TimeGAN_Model_Predictions' directory!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510c999",
   "metadata": {},
   "source": [
    "## Summary: TimeGAN Model Performance and Architecture\n",
    "\n",
    "### Model Overview:\n",
    "TimeGAN combines autoencoders with GANs to learn realistic temporal dynamics:\n",
    "- **Embedding Network**: Compresses high-dimensional time series into latent space\n",
    "- **Recovery Network**: Reconstructs original time series from embeddings\n",
    "- **Generator Network**: Creates synthetic sequences from random noise\n",
    "- **Discriminator Network**: Distinguishes real from synthetic sequences\n",
    "\n",
    "### Key Features:\n",
    "- Jointly trained on three objectives: Embedding MSE loss, Generator adversarial loss, Discriminator loss\n",
    "- Uses LSTM layers for temporal sequence modeling\n",
    "- Dropout layers prevent overfitting\n",
    "- Adam optimizer with learning rate 0.001\n",
    "\n",
    "### Training Configuration:\n",
    "- **Epochs**: 50\n",
    "- **Batch Size**: 32\n",
    "- **Sequence Length**: 30 days\n",
    "- **Latent Dimension**: 10\n",
    "- **Hidden Dimension**: 32\n",
    "- **Learning Rate**: 0.001 (Adam optimizer)\n",
    "\n",
    "### Evaluation Results:\n",
    "TimeGAN uses a unique architecture with 4 neural networks (Embedding, Recovery, Generator, Discriminator) working together. The model learns temporal dynamics through adversarial training and autoencoding. Performance depends on:\n",
    "- Quality of learned embeddings\n",
    "- Stability of GAN training\n",
    "- Cryptocurrency volatility patterns\n",
    "\n",
    "### Model Comparison (All Five Models):\n",
    "| Model | Best RÂ² | Average RÂ² | Complexity | Approach |\n",
    "|-------|---------|-----------|------------|----------|\n",
    "| **ARIMA** | 0.9939 | 0.9635 | Low | Statistical (backtesting) |\n",
    "| **LSTM** | 0.8957 | 0.8082 | Medium | Deep learning (supervised) |\n",
    "| **TimeGAN** | Varies | Varies | Very High | Generative (adversarial) |\n",
    "| **DDPM** | Varies | Varies | High | Diffusion (generative) |\n",
    "| **Prophet** | -1.5929 | -4.2121 | Low | Seasonal decomposition |\n",
    "\n",
    "\n",
    "### Recommendation:- **Research**: TimeGAN useful for data augmentation and understanding temporal patterns\n",
    "\n",
    "- **Best Overall**: ARIMA model with backtesting approach (RÂ² > 0.95)- **Production**: Ensemble approach combining ARIMA + LSTM recommended\n",
    "\n",
    "- **Deep Learning**: LSTM is more stable and accurate than TimeGAN for direct prediction- **Synthetic Data Generation**: TimeGAN's true strength - creating realistic training data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
